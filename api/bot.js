const { Telegraf } = require('telegraf');
const { OpenAI } = require('openai');

const bot = new Telegraf(process.env.TELEGRAM_TOKEN);
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Ð˜ÑÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
const conversations = new Map();

bot.start((ctx) => {
  ctx.reply('ðŸ¤– Ð¯ ChatGPT-Ð±Ð¾Ñ‚! Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð»ÑŽÐ±Ð¾Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ:');
});

bot.help((ctx) => {
  ctx.reply([
    'ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹:',
    '/new - ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³',
    '/mode [creative/balanced/precise] - Ð’Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ñ€ÐµÐ¶Ð¸Ð¼',
    '/help - Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ°'
  ].join('\n'));
});

bot.command('new', (ctx) => {
  conversations.delete(ctx.from.id);
  ctx.reply('ðŸ†• ÐÐ¾Ð²Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð½Ð°Ñ‡Ð°Ñ‚!');
});

bot.command('mode', (ctx) => {
  const mode = ctx.message.text.split(' ')[1];
  const validModes = ['creative', 'balanced', 'precise'];
  
  if (validModes.includes(mode)) {
    const user = conversations.get(ctx.from.id) || {};
    user.mode = mode;
    conversations.set(ctx.from.id, user);
    ctx.reply(`âœ… Ð ÐµÐ¶Ð¸Ð¼ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½ Ð½Ð°: ${mode}`);
  } else {
    ctx.reply('âŒ ÐÐµÐ²ÐµÑ€Ð½Ñ‹Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼. Ð”Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ñ‹: creative, balanced, precise');
  }
});

bot.on('text', async (ctx) => {
  try {
    const userId = ctx.from.id;
    const userMessage = ctx.message.text;

    // ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°
    const conversation = conversations.get(userId) || {
      messages: [],
      mode: 'balanced'
    };

    // Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
    conversation.messages.push({
      role: 'user',
      content: userMessage
    });

    // ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ Ñ€ÐµÐ¶Ð¸Ð¼Ñƒ
    const params = {
      model: 'gpt-3.5-turbo',
      messages: conversation.messages,
      temperature: 0.7, // creative: 1.0, precise: 0.3
      max_tokens: 1000
    };

    if (conversation.mode === 'creative') {
      params.temperature = 1.0;
      params.top_p = 0.9;
    } else if (conversation.mode === 'precise') {
      params.temperature = 0.3;
      params.top_p = 0.5;
    }

    // ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ð² OpenAI
    const response = await openai.chat.completions.create(params);
    const aiResponse = response.choices[0].message.content;

    // Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¸ Ð¾Ð±Ñ€ÐµÐ·Ð°ÐµÐ¼ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ
    conversation.messages.push({
      role: 'assistant',
      content: aiResponse
    });

    if (conversation.messages.length > 6) {
      conversation.messages = conversation.messages.slice(-4);
    }

    conversations.set(userId, conversation);

    // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŽ
    await ctx.reply(aiResponse, { parse_mode: 'Markdown' });

  } catch (error) {
    console.error('OpenAI Error:', error);
    ctx.reply('âš ï¸ ÐŸÑ€Ð¾Ð¸Ð·Ð¾ÑˆÐ»Ð° Ð¾ÑˆÐ¸Ð±ÐºÐ°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿ÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ');
  }
});

module.exports = async (req, res) => {
  await bot.handleUpdate(req.body, res);
};